import streamlit as st
import pandas as pd
import numpy as np
import chardet
import io

# 1. é¡µé¢é…ç½®
st.set_page_config(page_title="Tripeaks ç®—æ³•å¯¹æ¯”å¹³å° V1.9.11", layout="wide")
st.title("ğŸ´ Tripeaks ç®—æ³•å¯¹æ¯”ä¸æ·±åº¦å®¡è®¡å¹³å° V1.9.11")

# --- ã€å·¥å…·å‡½æ•°ï¼šç¡®ä¿æ—  NameErrorã€‘ ---
def get_col_safe(df, target_keywords):
    """é˜²æ­¢ç¼–ç ä¹±ç æˆ–ç©ºæ ¼å¯¼è‡´çš„ KeyError/NameError"""
    for col in df.columns:
        c_str = str(col).replace(" ", "").replace("\n", "")
        for key in target_keywords:
            if key in c_str:
                return col
    return None

def calculate_advanced_stats(series, trim_percentage):
    """åº•å±‚ç»Ÿè®¡å¼•æ“ï¼š15% æˆªæ–­ç»Ÿè®¡"""
    if len(series) < 5: 
        m = series.mean(); v = series.var()
        return m, v, (np.sqrt(v)/m if m > 0 else 0)
    sorted_s = np.sort(series)
    n = len(sorted_s)
    trim = int(n * (trim_percentage / 100))
    trimmed = sorted_s[trim : n - trim] if trim > 0 else sorted_s
    mu, var = np.mean(trimmed), np.var(trimmed)
    cv = (np.sqrt(var) / mu) if mu > 0 else 0
    return mu, var, cv

def audit_engine(row, col_map, base_init_score):
    """åº•å±‚å®¡è®¡è¯„åˆ†å¼•æ“ï¼šè®¡ç®—å•å±€å¾—åˆ†ä¸çº¢çº¿åˆ¤å®š"""
    try:
        seq_raw = str(row[col_map['seq']])
        seq = [int(x.strip()) for x in seq_raw.split(',') if x.strip() != ""]
        desk_init = row[col_map['desk']]
        diff = row[col_map['diff']]
        actual = str(row[col_map['act']])
    except: return 0, "è§£æå¤±è´¥", 0, 0, 0, 0, 0, 0

    score = base_init_score
    # A. æ­£å‘ä½“éªŒé¡¹
    if sum(seq[:3]) >= 4: score += 5
    if any(x >= 3 for x in seq[-5:]): score += 5
    if len(seq) >= 7 and max(seq) in seq[6:]: score += 5
    
    # B. è¿å‡»æ¥åŠ›
    eff_idx = [i for i, x in enumerate(seq) if x >= 3]
    relay = 0
    if len(eff_idx) >= 2:
        for i in range(len(eff_idx)-1):
            if (eff_idx[i+1]-eff_idx[i]-1) <= 1: relay += 1
    score += (10 if relay >= 3 else 7 if relay == 2 else 5 if relay == 1 else 0)

    # C. è´«ç˜ åŒºæ‰£åˆ†
    c1, c2, c3 = 0, 0, 0
    boundaries = [-1] + eff_idx + [len(seq)]
    for j in range(len(boundaries)-1):
        start, end = boundaries[j]+1, boundaries[j+1]
        inter = seq[start:end]
        if inter:
            L, Z = len(inter), inter.count(0)
            if L >= 6 or (L >= 4 and Z >= 3): c3 += 1; score -= (25 if start <= 2 else 20)
            elif L == 5 or (3 <= L <= 4 and Z == 2): c2 += 1; score -= 9
            elif L >= 3: c1 += 1; score -= 5

    # D. æŠ•å–‚é¡¹ä¸è‡ªåŠ¨åŒ–
    f1, f2, red_auto = 0, 0, False
    con_list = []
    cur = 0
    for x in seq:
        if x > 0: cur += 1
        else:
            if cur > 0: con_list.append(cur); cur = 0
    if cur > 0: con_list.append(cur)
    for fl in con_list:
        if fl >= 7: red_auto = True
        elif 5 <= fl <= 6: f2 += 1; score -= 9
        elif fl == 4: f1 += 1; score -= 3

    # E. çº¢çº¿åˆ¤å®š
    red_tags = []
    if max(seq) >= desk_init * 0.4: red_tags.append("æ•°å€¼å´©å")
    if red_auto: red_tags.append("è‡ªåŠ¨åŒ–å±€")
    if (diff <= 30 and "å¤±è´¥" in actual) or (diff >= 40 and "èƒœåˆ©" in actual): red_tags.append("é€»è¾‘è¿é€†")
    
    return score, ",".join(red_tags) if red_tags else "é€šè¿‡", c1, c2, c3, relay, f1, f2

# --- 2. ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    st.header("âš™ï¸ å®¡è®¡å…¨å±€å‚æ•°")
    base_score = st.slider("å®¡è®¡åˆå§‹åˆ† (Base)", 0, 100, 60)
    mu_limit = st.slider("åŠæ ¼é—¨æ§› (Î¼)", 0, 100, 70)
    st.divider()
    trim_val = st.slider("æˆªæ–­æ¯”ä¾‹ (%)", 0, 30, 15)
    cv_limit = st.slider("æœ€å¤§ CV (ç¨³å®šæ€§)", 0.05, 0.50, 0.20)
    var_limit = st.slider("æœ€å¤§æ–¹å·®ä¿æŠ¤", 10, 100, 25)
    uploaded_files = st.file_uploader("ğŸ“‚ ä¸Šä¼ å¤šä¸ªæ•°æ® (xlsx/csv)", type=["xlsx", "csv"], accept_multiple_files=True)

# --- 3. ä¸»è®¡ç®—ä¸å¯¹é½é€»è¾‘ ---
if uploaded_files:
    all_raw_dfs = []
    for f in uploaded_files:
        try:
            if f.name.endswith('.xlsx'): t_df = pd.read_excel(f)
            else:
                raw_b = f.read(); enc = chardet.detect(raw_b)['encoding'] or 'utf-8'
                t_df = pd.read_csv(io.BytesIO(raw_b), encoding=enc)
            t_df['__ORIGIN__'] = f.name 
            all_raw_dfs.append(t_df)
        except: st.error(f"è¯»å– {f.name} å¤±è´¥")

    if all_raw_dfs:
        df = pd.concat(all_raw_dfs, ignore_index=True)
        col_map = {
            'seq': get_col_safe(df, ['å…¨éƒ¨è¿å‡»']),
            'desk': get_col_safe(df, ['åˆå§‹æ¡Œé¢ç‰Œ']),
            'diff': get_col_safe(df, ['éš¾åº¦']),
            'act': get_col_safe(df, ['å®é™…ç»“æœ']),
            'hand': get_col_safe(df, ['åˆå§‹æ‰‹ç‰Œ']),
            'jid': get_col_safe(df, ['è§£é›†ID'])
        }

        # æ„å»ºç»Ÿä¸€äº‹å®è¡¨
        with st.spinner('å®¡è®¡å¼•æ“è®¡ç®—ä¸­...'):
            res = df.apply(lambda r: pd.Series(audit_engine(r, col_map, base_score)), axis=1)
            df[['å¾—åˆ†', 'çº¢çº¿åˆ¤å®š', 'c1', 'c2', 'c3', 'æ¥åŠ›', 'f1', 'f2']] = res

            fact_records = []
            h_col, j_col, d_col = col_map['hand'], col_map['jid'], col_map['diff']
            for (f_name, h_val, j_id, d_val), gp in df.groupby(['__ORIGIN__', h_col, j_col, d_col]):
                mu, var, cv = calculate_advanced_stats(gp['å¾—åˆ†'], trim_val)
                red_m = gp['çº¢çº¿åˆ¤å®š'] != "é€šè¿‡"
                
                reason = "âœ… é€šè¿‡"
                if red_m.mean() >= 0.15: reason = f"âŒ çº¢çº¿æ‹’ç» ({gp[red_m]['çº¢çº¿åˆ¤å®š'].mode()[0]})"
                elif mu < mu_limit: reason = "âŒ åˆ†å€¼æ‹’ç»"
                elif cv > cv_limit: reason = "âŒ ç¨³å®šæ€§æ‹’ç»"
                elif var > var_limit: reason = "âŒ æ³¢åŠ¨æ‹’ç» (æ–¹å·®è¶…æ ‡)"
                
                fact_records.append({
                    "æºæ–‡ä»¶": f_name, "åˆå§‹æ‰‹ç‰Œ": h_val, "è§£é›†ID": j_id, "éš¾åº¦": d_val,
                    "Î¼_å‡å€¼": mu, "ÏƒÂ²_æ–¹å·®": var, "CV": cv, "åˆ¤å®šç»“è®º": reason,
                    "is_pass": 1 if "âœ…" in reason else 0
                })
            df_fact = pd.DataFrame(fact_records)

        # === 4.1 æ€»ä½“ç®—æ³•ç­–ç•¥çœ‹æ¿ ===
        st.header("ğŸ“Š ç®—æ³•ç­–ç•¥çœ‹æ¿")
        summary_rows = []
        for h_v, gp_h in df_fact.groupby('åˆå§‹æ‰‹ç‰Œ'):
            diff_counts = gp_h[gp_h['is_pass'] == 1].groupby('éš¾åº¦').size().to_dict()
            total_pass_jid = gp_h[gp_h['is_pass'] == 1].drop_duplicates(subset=['æºæ–‡ä»¶', 'è§£é›†ID']).shape[0]
            total_unique_jid = gp_h.drop_duplicates(subset=['æºæ–‡ä»¶', 'è§£é›†ID']).shape[0]

            row = {"åˆå§‹æ‰‹ç‰Œæ•°": h_v, "ç‰Œé›†æ€»æ•°": total_unique_jid, "âœ… æ€»å»é‡é€šè¿‡æ•°": total_pass_jid, 
                   "èµ„æºè¦†ç›–ç‡": total_pass_jid / total_unique_jid if total_unique_jid > 0 else 0}
            for d in sorted(df_fact['éš¾åº¦'].unique()):
                row[f"éš¾åº¦{d}é€šè¿‡"] = diff_counts.get(d, 0)
            summary_rows.append(row)
        
        st.dataframe(pd.DataFrame(summary_rows).style.format({"èµ„æºè¦†ç›–ç‡":"{:.1%}"}), use_container_width=True)

        # === 4.2 ç‰Œé›†æ˜ç»†æ’è¡Œ ===
        st.divider()
        st.subheader("ğŸ¯ ç‰Œé›†æ˜ç»†æ’è¡Œ")
        f_h = st.multiselect("æ‰‹ç‰Œç»´åº¦", sorted(df_fact['åˆå§‹æ‰‹ç‰Œ'].unique()), default=sorted(df_fact['åˆå§‹æ‰‹ç‰Œ'].unique()))
        f_s = st.radio("åˆ¤å®šè¿‡æ»¤", ["å…¨éƒ¨", "é€šè¿‡", "æ‹’ç»"], horizontal=True)

        view_df = df_fact[df_fact['åˆå§‹æ‰‹ç‰Œ'].isin(f_h)].copy()
        if f_s == "é€šè¿‡": view_df = view_df[view_df['is_pass'] == 1]
        elif f_s == "æ‹’ç»": view_df = view_df[view_df['is_pass'] == 0]

        st.dataframe(view_df.drop(columns=['is_pass']).style.applymap(
            lambda x: 'color: #ff4b4b' if 'âŒ' in str(x) else 'color: #008000', subset=['åˆ¤å®šç»“è®º']
        ).format({"Î¼_å‡å€¼":"{:.2f}", "ÏƒÂ²_æ–¹å·®":"{:.2f}", "CV":"{:.3f}"}), use_container_width=True)

        st.info(f"ğŸ“Š æ•°æ®æ ¸å¯¹ï¼šå½“å‰æ˜ç»†è¡¨å…±æœ‰ {view_df[view_df['is_pass']==1].shape[0]} è¡Œé€šè¿‡è®°å½•ã€‚")
