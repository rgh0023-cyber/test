import streamlit as st
import pandas as pd
import numpy as np
import chardet
import io

# ... [ä¿ç•™ calculate_advanced_stats å’Œ audit_engine å‡½æ•°é€»è¾‘] ...

if uploaded_files:
    # 1. ä¸¥æ ¼è¯»å–
    all_raw_dfs = []
    for f in uploaded_files:
        try:
            if f.name.endswith('.xlsx'): t_df = pd.read_excel(f)
            else:
                r = f.read(); enc = chardet.detect(r)['encoding'] or 'utf-8'
                t_df = pd.read_csv(io.BytesIO(r), encoding=enc)
            t_df['__FILE__'] = f.name # å†…éƒ¨æ ‡è¯†åˆ—
            all_raw_dfs.append(t_df)
        except: st.error(f"è¯»å– {f.name} å‡ºé”™")

    if all_raw_dfs:
        full_df = pd.concat(all_raw_dfs, ignore_index=True)
        # è·å–åˆ—åæ˜ å°„
        c_m = {
            'seq': get_col_safe(full_df, ['å…¨éƒ¨è¿å‡»']),
            'desk': get_col_safe(full_df, ['åˆå§‹æ¡Œé¢ç‰Œ']),
            'diff': get_col_safe(full_df, ['éš¾åº¦']),
            'act': get_col_safe(full_df, ['å®é™…ç»“æœ']),
            'hand': get_col_safe(full_df, ['åˆå§‹æ‰‹ç‰Œ']),
            'jid': get_col_safe(full_df, ['è§£é›†ID'])
        }

        # --- æ ¸å¿ƒä¿®æ­£ï¼šæ„å»ºç»å¯¹å”¯ä¸€çš„ã€åˆ¤å†³æ˜ç»†åº“ã€‘ ---
        with st.spinner('æ„å»ºåˆ¤å†³æ˜ç»†åº“...'):
            # å…ˆç®—å•å±€å¾—åˆ†
            scr = full_df.apply(lambda r: pd.Series(audit_engine(r, c_m, base_score)), axis=1)
            full_df[['å¾—åˆ†', 'çº¢çº¿åˆ¤å®š', 'c1', 'c2', 'c3', 'æ¥åŠ›', 'f1', 'f2']] = scr

            final_judgments = []
            # å¿…é¡»åŒ…å«æ‰€æœ‰åŒºåˆ†ç»´åº¦ï¼šæºæ–‡ä»¶ã€æ‰‹ç‰Œæ•°ã€è§£é›†IDã€éš¾åº¦
            # ä¸è¿›è¡Œä»»ä½•æå‰å»é‡ï¼Œç¡®ä¿æ¯ä¸€ç»„æµ‹è¯•éƒ½è¢«è®°å½•
            g_keys = ['__FILE__', c_m['hand'], c_m['jid'], c_m['diff']]
            for keys, gp in full_df.groupby(g_keys):
                mu, var, cv = calculate_advanced_stats(gp['å¾—åˆ†'], trim_val)
                red_m = gp['çº¢çº¿åˆ¤å®š'] != "é€šè¿‡"
                r_rate = red_m.mean()
                
                # åˆ¤å®š
                reason = "âœ… é€šè¿‡"
                if r_rate >= 0.15: reason = f"âŒ çº¢çº¿æ‹’ç» ({gp[red_m]['çº¢çº¿åˆ¤å®š'].mode()[0]})"
                elif mu < mu_limit: reason = "âŒ åˆ†å€¼æ‹’ç»"
                elif cv > cv_limit: reason = "âŒ ç¨³å®šæ€§æ‹’ç»"
                elif var > var_limit: reason = "âŒ æ³¢åŠ¨æ‹’ç» (æ–¹å·®è¶…æ ‡)"
                
                final_judgments.append({
                    "UID": f"{keys[0]}_{keys[1]}_{keys[2]}_{keys[3]}", # ç»å¯¹å”¯ä¸€æ ‡è¯†
                    "æºæ–‡ä»¶": keys[0], "æ‰‹ç‰Œæ•°": keys[1], "è§£é›†ID": keys[2], "éš¾åº¦": keys[3],
                    "Î¼_å‡å€¼": mu, "ÏƒÂ²_æ–¹å·®": var, "CV": cv, "åˆ¤å®šç»“è®º": reason,
                    "is_pass": 1 if "âœ…" in reason else 0
                })
            
            # æ‰€æœ‰çš„ç»Ÿè®¡å’Œå±•ç¤ºåªè®¤è¿™ä¸ª df_base
            df_base = pd.DataFrame(final_judgments)

        # === 1. çœ‹æ¿å±•ç¤º (ä» df_base è®¡æ•°) ===
        st.header("ğŸ“Š ç®—æ³•ç­–ç•¥çœ‹æ¿")
        summary_data = []
        for h_v, gp_h in df_base.groupby('æ‰‹ç‰Œæ•°'):
            # å„éš¾åº¦é€šè¿‡æ•° (é€šè¿‡è®¡æ•°è¡Œæ•°)
            d_counts = gp_h[gp_h['is_pass'] == 1].groupby('éš¾åº¦').size().to_dict()
            # å»é‡æ€»é€šè¿‡æ•° (åŸºäº ID å»é‡)
            unique_pass = gp_h[gp_h['is_pass'] == 1].drop_duplicates(subset=['æºæ–‡ä»¶', 'è§£é›†ID']).shape[0]
            total_unique = gp_h.drop_duplicates(subset=['æºæ–‡ä»¶', 'è§£é›†ID']).shape[0]

            row = {
                "åˆå§‹æ‰‹ç‰Œæ•°": h_v,
                "ç‰Œé›†æ€»æ•°": total_unique,
                "âœ… æ€»å»é‡é€šè¿‡æ•°": unique_pass,
                "èµ„æºè¦†ç›–ç‡": unique_pass / total_unique if total_unique > 0 else 0
            }
            # åŠ¨æ€æ·»åŠ åˆ—ï¼šéš¾åº¦Xé€šè¿‡
            for d in sorted(df_base['éš¾åº¦'].unique()):
                row[f"éš¾åº¦{d}é€šè¿‡"] = d_counts.get(d, 0)
            summary_data.append(row)
        
        st.dataframe(pd.DataFrame(summary_data).style.format({"èµ„æºè¦†ç›–ç‡":"{:.1%}"}), use_container_width=True)

        # === 2. æ˜ç»†æ’è¡Œ (ä» df_base å±•ç¤º) ===
        st.divider()
        st.subheader("ğŸ¯ ç‰Œé›†æ˜ç»†æ’è¡Œ")
        # ç­›é€‰å™¨
        f_h = st.multiselect("æ‰‹ç‰Œç»´åº¦", sorted(df_base['æ‰‹ç‰Œæ•°'].unique()), default=sorted(df_base['æ‰‹ç‰Œæ•°'].unique()))
        f_s = st.radio("åˆ¤å®šè¿‡æ»¤", ["å…¨éƒ¨", "é€šè¿‡", "æ‹’ç»"], horizontal=True)

        # ç­›é€‰é€»è¾‘ï¼šåªåšè¡Œè¿‡æ»¤ï¼Œä¸åšä»»ä½•åˆå¹¶
        view_df = df_base[df_base['æ‰‹ç‰Œæ•°'].isin(f_h)].copy()
        if f_s == "é€šè¿‡": view_df = view_df[view_df['is_pass'] == 1]
        elif f_s == "æ‹’ç»": view_df = view_df[view_df['is_pass'] == 0]

        # æ ¸å¿ƒæ ¸å¯¹ç‚¹ï¼šè¿™é‡Œçš„ view_df.shape[0] å¿…é¡»èƒ½æ¨å¯¼å‡ºçœ‹æ¿çš„æ•°å­—
        st.dataframe(view_df.drop(columns=['UID', 'is_pass']).style.applymap(
            lambda x: 'color: #ff4b4b' if 'âŒ' in str(x) else 'color: #008000', subset=['åˆ¤å®šç»“è®º']
        ).format({"Î¼_å‡å€¼":"{:.2f}", "ÏƒÂ²_æ–¹å·®":"{:.2f}", "CV":"{:.3f}"}), use_container_width=True)

        # åº•éƒ¨æ ¸å¯¹ä¿¡æ¯
        pass_count = view_df[view_df['is_pass'] == 1].shape[0]
        st.info(f"æ•°æ®å¯¹é½æ ¸æŸ¥ï¼šå½“å‰åˆ—è¡¨ä¸­ã€åˆ¤å®šç»“è®ºã€ä¸ºé€šè¿‡çš„è¡Œæ•°å…±æœ‰ **{pass_count}** è¡Œã€‚è¯·æ ¸å¯¹æ˜¯å¦ç­‰äºçœ‹æ¿ä¸­å¯¹åº”åˆ—çš„æ•°å­—ä¹‹å’Œã€‚")
