import streamlit as st
import pandas as pd
import numpy as np
import chardet
import io

# --- [åº•å±‚æ ¸å¿ƒç®—æ³•é€»è¾‘ï¼šå®Œå…¨é”å®šï¼Œä¸¥ç¦ä¿®æ”¹] ---
# ... (æ­¤å¤„åŒ…å« calculate_advanced_stats å’Œ audit_engineï¼Œé€»è¾‘ä¸ V1.9.1 ä¿æŒ 100% ä¸€è‡´) ...

# --- [æ•°æ®æµæ•´æ”¹éƒ¨åˆ†] ---
if uploaded_files:
    # 1. åŸå§‹æ•°æ®åŠ è½½ (ä¿ç•™æºæ–‡ä»¶æ ‡è¯†)
    all_data_list = []
    for f in uploaded_files:
        try:
            if f.name.endswith('.xlsx'): temp_df = pd.read_excel(f)
            else:
                raw_b = f.read(); enc = chardet.detect(raw_b)['encoding'] or 'utf-8'
                temp_df = pd.read_csv(io.BytesIO(raw_b), encoding=enc)
            temp_df['__ORIGIN__'] = f.name 
            all_data_list.append(temp_df)
        except: st.error(f"è¯»å– {f.name} å¤±è´¥")

    if all_data_list:
        df = pd.concat(all_data_list, ignore_index=True)
        col_map = {
            'seq': get_col_safe(df, ['å…¨éƒ¨è¿å‡»']), 'desk': get_col_safe(df, ['åˆå§‹æ¡Œé¢ç‰Œ']),
            'diff': get_col_safe(df, ['éš¾åº¦']), 'act': get_col_safe(df, ['å®é™…ç»“æœ']),
            'hand': get_col_safe(df, ['åˆå§‹æ‰‹ç‰Œ']), 'jid': get_col_safe(df, ['è§£é›†ID'])
        }

        # --- ç¬¬ä¸€æ­¥ï¼šæ„å»ºã€å”¯ä¸€åˆ¤å®šäº‹å®è¡¨ã€‘ ---
        # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†ç¡®ä¿çœ‹æ¿å’Œæ˜ç»†è¡¨å¼•ç”¨çš„â€œåˆ¤å®šç»“æœâ€æ¥æºäºåŒä¸€ä¸ªå†…å­˜å˜é‡
        with st.spinner('åŒæ­¥å®¡è®¡å¼•æ“æ•°æ®...'):
            # æ‰§è¡Œå®¡è®¡å¼•æ“è®¡ç®—
            res = df.apply(lambda r: pd.Series(audit_engine(r, col_map, base_score)), axis=1)
            df[['å¾—åˆ†', 'çº¢çº¿åˆ¤å®š', 'c1', 'c2', 'c3', 'æ¥åŠ›', 'f1', 'f2']] = res

            # æ„å»ºåˆ¤å†³æ˜ç»†è¡¨ï¼ˆåˆ¤å®šäº‹å®è¡¨ï¼‰
            # æˆ‘ä»¬é€šè¿‡ [æºæ–‡ä»¶, åˆå§‹æ‰‹ç‰Œ, è§£é›†ID, éš¾åº¦] é”å®šå”¯ä¸€æ€§
            audit_fact_list = []
            h_col, j_col, d_col = col_map['hand'], col_map['jid'], col_map['diff']
            
            for (f_name, h_val, j_id, d_val), gp in df.groupby(['__ORIGIN__', h_col, j_col, d_col]):
                mu, var, cv = calculate_advanced_stats(gp['å¾—åˆ†'], trim_val)
                red_m = gp['çº¢çº¿åˆ¤å®š'] != "é€šè¿‡"
                r_rate = red_m.mean()
                
                # åˆ¤å®šå±‚çº§å¯¹é½
                reason = "âœ… é€šè¿‡"
                if r_rate >= 0.15: reason = f"âŒ çº¢çº¿æ‹’ç» ({gp[red_m]['çº¢çº¿åˆ¤å®š'].mode()[0]})"
                elif mu < mu_limit: reason = "âŒ åˆ†å€¼æ‹’ç»"
                elif cv > cv_limit: reason = "âŒ ç¨³å®šæ€§æ‹’ç»"
                elif var > var_limit: reason = "âŒ æ³¢åŠ¨æ‹’ç» (æ–¹å·®è¶…æ ‡)"
                
                audit_fact_list.append({
                    "æºæ–‡ä»¶": f_name, "åˆå§‹æ‰‹ç‰Œ": h_val, "è§£é›†ID": j_id, "éš¾åº¦": d_val,
                    "Î¼_å‡å€¼": mu, "ÏƒÂ²_æ–¹å·®": var, "CV": cv, "åˆ¤å®šç»“è®º": reason,
                    "is_pass": 1 if "âœ…" in reason else 0
                })
            
            # è¿™å¼ è¡¨æ˜¯çœ‹æ¿å’Œæ˜ç»†çš„â€œå”¯ä¸€çœŸç›¸â€
            df_fact = pd.DataFrame(audit_fact_list)

        # === 2. æ€»ä½“ç­–ç•¥çœ‹æ¿ (åŸºäº df_fact è®¡æ•°) ===
        st.header("ğŸ“Š ç®—æ³•ç­–ç•¥çœ‹æ¿")
        strat_summary = []
        for h_v, gp_h in df_fact.groupby('åˆå§‹æ‰‹ç‰Œ'):
            # A. åˆ†éš¾åº¦ç»Ÿè®¡é€šè¿‡æ•° (æ­¤æ—¶ä¸å†å»é‡è§£é›†IDï¼Œæ¯ä¸ªéš¾åº¦ç‹¬ç«‹è®¡æ•°)
            diff_summary = gp_h[gp_h['is_pass'] == 1].groupby('éš¾åº¦').size().to_dict()
            
            # B. æ€»å»é‡é€šè¿‡æ•° (åŒä¸€è§£é›†IDåœ¨ä»»ä¸€éš¾åº¦é€šè¿‡å³è®¡ä¸º1)
            # è¿™é‡Œå¿…é¡»æŒ‰ [æºæ–‡ä»¶ + è§£é›†ID] å»é‡ï¼Œé˜²æ­¢è·¨æ–‡ä»¶IDé‡å¤
            pass_jid_set = gp_h[gp_h['is_pass'] == 1].drop_duplicates(subset=['æºæ–‡ä»¶', 'è§£é›†ID'])
            total_distinct_pass = len(pass_jid_set)
            
            # C. æ€»èµ„æºæ•° (å»é‡åçš„è§£é›†æ€»æ•°)
            total_jids = gp_h.drop_duplicates(subset=['æºæ–‡ä»¶', 'è§£é›†ID']).shape[0]

            row = {
                "åˆå§‹æ‰‹ç‰Œæ•°": h_v,
                "ç‰Œé›†æ€»æ•°": total_jids,
                "âœ… æ€»å»é‡é€šè¿‡æ•°": total_distinct_pass,
                "èµ„æºè¦†ç›–ç‡": total_distinct_pass / total_jids if total_jids > 0 else 0
            }
            # å¡«å……å„éš¾åº¦é€šè¿‡åˆ—
            for d in sorted(df_fact['éš¾åº¦'].unique()):
                row[f"éš¾åº¦{d}é€šè¿‡"] = diff_summary.get(d, 0)
            strat_summary.append(row)
        
        st.dataframe(pd.DataFrame(strat_summary).style.format({"èµ„æºè¦†ç›–ç‡":"{:.1%}"}), use_container_width=True)

        # === 3. ç‰Œé›†æ˜ç»†æ’è¡Œ (ç›´æ¥å±•ç¤º df_fact) ===
        st.divider()
        st.subheader("ğŸ¯ ç‰Œé›†æ˜ç»†æ’è¡Œ")
        
        # ç­›é€‰å™¨é€»è¾‘
        f_h = st.multiselect("æ‰‹ç‰Œç­›é€‰", sorted(df_fact['åˆå§‹æ‰‹ç‰Œ'].unique()), default=sorted(df_fact['åˆå§‹æ‰‹ç‰Œ'].unique()))
        f_s = st.radio("åˆ¤å®šè¿‡æ»¤", ["å…¨éƒ¨", "é€šè¿‡", "æ‹’ç»"], horizontal=True)

        # æ ¸å¿ƒï¼šç›´æ¥ä» df_fact è¿‡æ»¤ï¼Œä¸è¿›è¡Œä»»ä½•èšåˆï¼Œç¡®ä¿æ‰€è§å³æ‰€å¾—
        view_df = df_fact[df_fact['åˆå§‹æ‰‹ç‰Œ'].isin(f_h)].copy()
        if f_s == "é€šè¿‡": view_df = view_df[view_df['is_pass'] == 1]
        elif f_s == "æ‹’ç»": view_df = view_df[view_df['is_pass'] == 0]

        st.dataframe(view_df.drop(columns=['is_pass']).style.applymap(
            lambda x: 'color: #ff4b4b' if 'âŒ' in str(x) else 'color: #008000', subset=['åˆ¤å®šç»“è®º']
        ).format({"Î¼_å‡å€¼":"{:.2f}", "ÏƒÂ²_æ–¹å·®":"{:.2f}", "CV":"{:.3f}"}), use_container_width=True)

        # å¼ºåŠ›æ ¡éªŒ
        st.info(f"ğŸ’¡ å¯¹é½è‡ªæ£€ï¼šå½“å‰æ˜ç»†è¡¨æ˜¾ç¤ºçš„é€šè¿‡æ¡ç›®æ•°ä¸º **{view_df[view_df['is_pass']==1].shape[0]}** è¡Œã€‚è¿™åº”è¯¥ç­‰äºçœ‹æ¿ä¸­å¯¹åº”è¡Œå„éš¾åº¦é€šè¿‡æ•°çš„åŠ æ€»ã€‚")
